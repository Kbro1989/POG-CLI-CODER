Console Logo
Search (/) for resources, docs, products, and more

Model Garden
Model Collections

Google models
123

Partner models
47

Self-deploy partner models
16
Tasks

Image classification
27

Object detection
28

Text classification
54

Entity extraction
41

Image segmentation
10

Image generation
36

Text generation
84

Image understanding
27

Text embeddings
23

Tabular classification
13

Document processing
13

Translation
40

Image retrieval
2

Video classification
2

Open vocabulary detection
3

Open vocabulary segmentation
2

Radiology
3

Health & Life Sciences
8

Video generation
15

Multimodal generation
24

Pathology
3

Dermatology
3

Audio generation
11

Text-to-speech
3

Multimodal embeddings
5

Speech recognition
2

Video understanding
1

Geospatial
3
Providers

Google
123

Salesforce
3

Meta
22

Stability.ai
4

Mistral AI
9

Anthropic
7

AI21
1

CSM
1

Qodo
1

CAMB.AI
1

Virtue AI
1

Contextual AI
1

Mongodb
5

Writer
1

NVIDIA
3

Ai2
1
Features

Open source
143

Notebook support
144

API available
5

Pipeline support
3

One-click deployment
108

Vertex AI Studio
37

Deploy on GKE
20

Demo available
26
Search models
What's new in Model Garden

TranslateGemma, MedGemma 1.5, FunctionGemma, and T5Gemma 2 available on Vertex
TranslateGemma, MedGemma 1.5, FunctionGemma, and T5Gemma 2 available on Vertex

Serving with G4 VM
G4 VMs with RTX PRO 6000 Blackwell GPUs are available on Vertex

GLM 4.7 and DeepSeek-V3.2 available
GLM 4.7 and DeepSeek-v3.2 through managed API and self-hosted deployment

Model co-hosting with dynamic loading and unloading
Use Vertex model co-hosting vLLM container to serve multiple models on the same VM

Provisioned Throughput support for Open Source models
OSS models are now available with Provisioned Throughput support

Gemini 3
Gemini 3 is now available on Vertex.
Browse, customize, and deploy machine learning models with Model Garden. Choose from models created by Google and other providers.

Sort by: TrendingLatest
Foundation models
Pre-trained multi-task models that can be further tuned or customized for specific tasks.


Gemini 3 Flash Preview
Our agentic workhorse model, bringing near Pro agentic, coding and multimodal intelligence, with more balanced cost and speed.


Gemini 3 Pro Image Preview
Our standard model upgraded for rapid creative workflows with image generation and conversational, multi-turn editing capabilities.


Gemini 3 Pro Preview
Our most powerful agentic and coding model, with the best multimodal understanding capabilities.


Gemini 2.5 Flash-Lite Preview
Most balanced Gemini model for low latency use cases.


Gemini 2.5 Flash Preview
Strong overall performance and low latency.


Gemini 2.5 Flash-Lite
Most balanced Gemini model for low latency use cases.


Gemini 2.5 Pro
Strongest model quality, especially for code & complex prompts.


Gemini 2.5 Flash
Best for balancing reasoning and speed


Gemini 2.0 Flash-Lite
Our cost-effective Gemini model to support high throughput.


Gemini 2.0 Flash
Workhorse model for all daily tasks. Strong overall performance and low latency supports real-time Live API.


Gemini Computer Use Preview
Power agents capable of interacting with user interfaces (UIs), such as browsers and web applications


Gemini 2.5 Flash Image (Nano Banana)
Our standard model upgraded for rapid creative workflows with image generation and conversational, multi-turn editing capabilities.


Gemini 2.5 Flash Image Preview
Our standard model upgraded for rapid creative workflows with image generation and conversational, multi-turn editing capabilities.


Veo 3.1 Fast for Video Generation
Use text prompts or static image + text prompts to generate novel videos with audio.


Veo 3.1 for Video Generation
Use text prompts or static image + text prompts to generate novel videos with audio.


Veo 3.1 for Video Generation
Use text prompts or static image + text prompts to generate novel videos with audio.


Imagen 4 Ultrafor Image Generation
Use text prompts to generate novel images.


Imagen 4 for Image Generation
Use text prompts to generate novel images.


Imagen 4 Fast for Image Generation
Use text prompts to generate novel images.


Imagen for Editing and Customization
Use text prompts to edit existing input images, or parts of an image with a mask or generate new images based upon the context provided by input reference images.


Veo 3 for Video Generation
Use text prompts or static image + text prompts to generate novel videos with audio.


Veo 3 Fast for Video Generation
Use text prompts or static image + text prompts to generate novel videos with audio.


Imagen 4 Ultra for Image Generation
Use text prompts to generate novel images.


Imagen 4 Fast for Image Generation
Use text prompts to generate novel images.


Imagen 4 for Image Generation
Use text prompts to generate novel images.


Veo 3 for Video Generation
Use text prompts or static image + text prompts to generate novel videos with audio.


Lyria 2 for Music Generation
Lyria 2 is a latent text-to-audio diffusion model capable of generating high-quality instrumental music from text input.


Imagen for Generation
Use text prompts to generate novel images.


Imagen for Editing and Customization
Use text prompts to edit existing input images, or parts of an image with a mask or generate new images based upon the context provided by input reference images.


Imagen 2 for Generation and Editing
Use text prompts to generative novel images, edit existing ones, edit parts of an image with a mask and more.


Claude Opus 4.5
Anthropic's most powerful model yet and the state-of-the-art coding model.


Claude Haiku 4.5
The next generation of Anthropic's fastest and most cost-effective model, optimal for use cases where speed and affordability matter.


Claude Sonnet 4.5
Anthropic's industry-leading model for high-volume uses in coding, in-depth research, agents, & more.


Claude Opus 4.1
The next generation of Anthropic’s most powerful model yet, Claude Opus 4.1 is an industry leader for coding. It delivers sustained performance on long-running tasks that require focused effort and thousands of steps, significantly expanding what AI agents can solve. Claude Opus 4.1 is ideal for powering frontier agent products and features.


Claude Opus 4
Anthropic’s most powerful model yet and the state-of-the-art coding model. It delivers sustained performance on long-running tasks that require focused effort and thousands of steps, significantly expanding what AI agents can solve. Claude Opus 4 is ideal for powering frontier agent products and features.


Claude Sonnet 4
Anthropic's mid-size model with superior intelligence for high-volume uses in coding, in-depth research, agents, & more.


Claude 3 Haiku
Claude 3 Haiku is Anthropic's fastest vision and text model for near-instant responses to simple queries, meant for seamless AI experiences mimicking human interactions.


FunctionGemma
Lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models


EmbeddingGemma
Lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models


Gemma 3n
Lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models


MedGemma
Collection of Gemma 3 variants that are trained for performance on medical text and image comprehension.


Gemma 3
Lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models


ShieldGemma 2
Lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models


Gemma 2
Lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models


PaliGemma 1 & 2
Lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models


Gemma
Lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models


CodeGemma
Lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models


Llama 4 API Service
Access Meta's Llama 4 models as a fully managed Vertex AI service


Llama 4
Explore and build with Llama 4 models on Vertex AI.


Sesame CSM
Speech generation model that generates audio from text and audio inputs.


Llama 3.1
SoTA open LLM built by Meta.


Llama 3.3
Explore and build with Llama 3.3 models on Vertex AI.


Llama 3.2
SoTA open LLM built by Meta.


Llama 3.3 API Service
Access Meta's Llama 3.3 models as a fully managed Vertex AI service


Llama 3.2 API Service
Access Meta's Llama 3.2 models as a fully managed Vertex AI service


Llama 3
SoTA open LLM built by Meta.


Veo 2 for Generation
Use text prompts to generate high-quality, realistic videos.


Llama 3.1 API Service
Access Meta's Llama 3.1 models as a fully managed Vertex AI service


Llama Guard
Explore and build with Meta's Llama Guard models on Vertex AI.


Prompt Guard
Explore and build with Meta's Prompt Guard models on Vertex AI.


Llama 2
SoTA open LLM built by Meta.


Codestral 2
A cutting-edge model specifically designed for code generation, including fill-in-the-middle and code completion.


Mistral Medium 3
Mistral Medium is an advanced Large Language Model (LLM) with state-of-the-art reasoning, knowledge and coding capabilities.


Mistral OCR (25.05)
Fast and accurate model to convert documents to markdown with interleaved images and text


Codestral (25.01) (Self-Deploy)
A cutting-edge model specifically designed for code generation, including fill-in-the-middle and code completion.


Mistral Small 3.1 (25.03)
Mistral Small 3.1 (25.03) is the enhanced version of Mistral Small 3, featuring multimodal capabilities and an extended context length of up to 128k.


Jamba Large 1.6
Jamba Large 1.6 offers fast, high-quality performance with superior long context handling and speed.


MARS7
Hyper-realistic text to speech in 10+ languages.


Mixtral
A Mixture of Experts LLM series developed by Mistral AI.


TranslateGemma
A new family of open machine translation models based on the powerful Gemma 3 foundation.


GLM 4.7 API Service
Access the GLM 4.7 model as a fully managed Vertex AI service


NVIDIA Nemotron V3
Serve NVIDIA Nemotron V3 on Vertex AI.


MedASR
MedASR is an automatic speech recognition (ASR) model that has been trained for the medical domain.


Ministral 3
State-of-the-art Ministral 3 family of models.


Mistral Large 3
General-purpose Multimodal granular Mixture-of-Experts model.


DeepSeek V3.2 API Service
Access the DeepSeek V3.2 model as a fully managed Vertex AI service


Qwen3 Embedding
Converts text data into numerical vectors that capture the meaning and relationships between words and phrases.


WeatherNext 2
State-of-the-art AI weather forecasting. Fast, efficient, and more accurate than current medium-range systems.


Kimi K2 Thinking API Service
Access the Kimi K2 Thinking model as a fully managed Vertex AI service


MiniMax-M2
Serve MiniMax-M2 on Vertex AI.


MiniMax-M2 API Service
Access the MiniMax-M2 model as a fully managed Vertex AI service


DeepSeek OCR API Service
Access the DeepSeek OCR model as a fully managed Vertex AI service


DeepSeek-OCR
Serve with deepseek-ai/DeepSeek-OCR.


NVIDIA Nemotron Nano v2 12B VL
An efficient 12B multimodal model for fast video and document understanding on text, video, and images.


Imagery - Classification and Retrieval for Remote Sensing
A vision-language model for zero-shot classification and retrieval of aerial and satellite images


Imagery - Object Detection for Remote Sensing
An open-vocabulary object detection model for aerial and satellite images


Palmyra X4 (Self-Deploy)
Top-ranked on Stanford HELM, WRITER's Palmyra X4 achieves superior performance on complex tasks and agentic workflows.


DeepSeek-V3.2
Serve with deepseek-ai/deepseek-V3.2 models.


Veo 3.1 Fast for Video Generation
Use text prompts or static image + text prompts to generate novel videos with audio.


Qwen3-Next
Explore and build with Qwen3 Next models on Vertex AI.


Qwen3-Next Instruct API Service
Access the Qwen3-Next Instruct model as a fully managed Vertex AI service


Qwen3-Next Thinking API Service
Access the Qwen3-Next Thinking model as a fully managed Vertex AI service


SEA-LION v4
A collection of Large Language Models pretrained and instruct-tuned for the Southeast Asia region.


DeepSeek V3.1 API Service
Access the DeepSeek V3.1 model as a fully managed Vertex AI service


DeepSeek-V3.1
Serve with deepseek-ai/deepseek-V3.1 models.


GLM-4.5
Foundation models designed for intelligent agents


Wan 2.2
Explore and build with Wan2.2 models on Vertex AI.


Qwen-Image
Qwen's image generation model for complex text rendering and precise image editing


Qwen3-VL
Qwen's vision-language model with major improvements across multiple dimensions, including understanding and generating text, perceiving and reasoning about visual content, supporting longer context lengths, understanding spatial relationships and dynamic videos, and interacting with AI agents.


GPT OSS API Service
Access GPT OSS models as a fully managed Vertex AI service


GPT OSS
OpenAI's open-weight models designed for powerful reasoning, agentic tasks, and versatile developer use cases


Qwen3-Coder
Explore and build with Qwen3 Coder models on Vertex AI.


Qwen3 Coder API Service
Access Qwen3 Coder model as a fully managed Vertex AI service


Qwen3 235B Instruct API Service
Access the Qwen3 235B Instruct model as a fully managed Vertex AI service


Kimi-K2
Explore and build with Kimi-K2 models on Vertex AI.


Wan 2.1
Explore and build with Wan2.1 models on Vertex AI.


Virtual Try-On
Virtual Try-On is a fully managed Vertex AI service to generate images of persons modeling fashion products.


T5Gemma
Lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models


MedSigLIP
SigLIP variant that is trained to encode medical images and text into a common embedding space.


BGE
Serve with BAAI BGE series models.


Veo 3 Fast for Video Generation
Use text prompts or static image + text prompts to generate novel videos with audio.


DeepSeek R1 0528 API Service
Access the DeepSeek R1 0528 model as a fully managed Vertex AI service


Imagen Product Recontext
Product Recontext is a fully managed Vertex AI service to generate images of products in new scenes and contexts.


Chirp 3
Chirp 3 is the latest generation of Google's multilingual ASR-specific generative models.


Gemini Embedding 001
Converts text data into vector representations for semantic search, classification, clustering, and similar tasks.


Qwen3
Explore and build with Qwen3 models on Vertex AI.


HiDream-I1
17B text-to-image model achieving image quality across diverse styles


Dia-1.6B
Compact text-to-speech model generating realistic dialogue with emotion control.


QwQ
Explore and build with QwQ models on Vertex AI.


CogVideoX-2b
Explore and build with CogVideoX-2b on Vertex AI.


TxGemma
TxGemma generates predictions, classifications or text based on therapeutic related data and can be used to efficiently build AI models for therapeutic-related tasks with less data and less compute.


HeAR
HeAR produces embeddings based on audio clips of health-related sounds that can be used to efficiently train classifier models for health acoustic related tasks with less data and less compute.


Phi-4
Explore and build with Phi-4 models on Vertex AI.


DeepSeek-R1
Serve with deepseek-ai/deepseek-r1 models.


DeepSeek-V3
Serve with deepseek-ai/deepseek-v3 models.


WeatherNext Demo
State-of-the-art weather forecasting, powered by AI. Fast, efficient, and more accurate than the best medium range systems in use today.


Nvidia Cosmos
Nvidia Cosmos World Foundation Models


Path Foundation
Path Foundation produces embeddings that can be used to efficiently train classifier models for pathology analysis tasks on H&E patches from whole slide images with less data and less compute.


Derm Foundation
Derm Foundation produces embeddings that can be used to efficiently train classifier models for dermatology-related tasks on photographs of human skin with less data and less compute.


Whisper Large
Whisper Large is OpenAI's state-of-the-art model for automatic speech recognition (ASR).


Chirp 2
Chirp 2 is a multilingual automatic speech recognition (ASR) model developed by Google that transcribes speech (Speech-to-Text).


Vertex Image Segmentation
Segment images and generate masks with a fully managed Vertex AI service.


Flux
A low latency text-to-image generation model created by Black Forest Labs


Phi-3
Explore and build with Phi-3 models on Vertex AI.


Qwen2 & Qwen2.5
Explore and build with Qwen2 and Qwen2.5 models on Vertex AI.


MaMMUT
A simple vision-encoder and text-decoder architecture for multimodal tasks.


E5 Text Embedding
Converts text data into numerical vectors that capture the meaning and relationships between words and phrases.


TimesFM
TimesFM (Time Series Foundation Model) is a pretrained time-series foundation model developed by Google Research for univariate time-series forecasting.


Stable Diffusion XL Lightning
A low latency text-to-image generation model based on Stable Diffusion XL.


Instant ID
An identity-preserving text-to-image generation model.


Stable Diffusion XL LCM
A Latent Consistency Model for low latency text-to-image generation based on Stable Diffusion XL.


LLaVA 1.5 & LLaVA-NeXT
Deploy LLaVA 1.5 and LLaVA-NeXT on Vertex AI.


LaMa (Large Mask Inpainting)
Resolution-robust large mask inpainting with Fourier convolutions.


Vicuna
Vicuna is a LLM trained by fine-tuning Llama 2 on user-shared conversation from ShareGPT.


BioGPT
BioGPT is a domain-specific generative transformer language model pre-trained on large-scale biomedical literature.


OWL-ViT v2
OWL-ViT v2 is an open vocabulary image object detection model.


DITO
DITO is an open vocabulary image object detection and segmentation model.


BiomedCLIP
Zero-shot image classification with the BiomedCLIP biomedical vision-language foundation model.


Mistral Self-host (7B & Nemo)
Mistral is a family of language model engineered for superior performance and efficiency.


ImageBind
Deploy Meta's ImageBind model on Vertex AI.


NLLB
NLLB (No Language Left Behind) is a large language model for machine translation supporting 200 languages.


Code Llama
Meta's family of code models designed for code synthesis, understanding and instruction available in four sizes.


CXR Foundation
CXR Foundation produces embeddings based on images of chest X-rays that can be used to efficiently train classifier models for chest X-ray related tasks with less data and less compute.


Stable Diffusion XL
Latent text-to-image diffusion model capable of generating high fidelity images given a text input.


OpenCLIP
OpenCLIP is an open source implementation of OpenAI CLIP model.


F-VLM [Deprecated]
F-VLM is an open vocabulary image object detection model.


Llama 2 (Quantized)
SoTA open LLM built by Meta.


Stable Diffusion v2.1
Latent text-to-image diffusion model taking as input a text prompt, and generates an image.


BERT (PEFT)
Finetune and deploy BERT with PEFT.


Falcon-instruct (PEFT)
Finetune and deploy Falcon-instruct with PEFT.


OpenLLaMA (PEFT)
Finetune and deploy OpenLLaMA with PEFT.


RoBERTa-large (PEFT)
Finetune and deploy RoBERTa-large with PEFT.


XLM-RoBERTa-large (PEFT)
Finetune and deploy XLM-RoBERTa-large with PEFT.


Stable-diffusion-4x-upscaler
Stable Diffusion 4x upscaler is a text-conditioned latent diffusion model capable of upscaling images to 4x resolution.


Segment Anything (SAM)
Segment Anything (SAM) is a state-of-the-art foundational image segmentation model.


Bart-large-cnn
A transformer-based seq2seq model with a bidirectional encoder and an autoregressive decoder.


Imagen for Captioning & VQA
Imagen Captioning generates a relevant description for a given image.


Label detector (PaLI zero-shot)
Detects custom labels in images without any additional training or fine tuning.


Embeddings for Text
Converts text data into vector representations for semantic search, classification, clustering, and similar tasks.


Embeddings for Text
Converts text data into vector representations for semantic search, classification, clustering, and similar tasks.


T5-FLAN
T5 (Text-To-Text Transfer Transformer) model with the T5-FLAN checkpoint.


T5-1.1
T5 (Text-To-Text Transfer Transformer) is a text-to-text encoder-decoder model built by Google.


BLIP2
BLIP2 is for the image captioning and visual-question-answering tasks.


InstructPix2Pix
A text conditioned image editing model based on Stable Diffusion.


Stable Diffusion Inpainting
Stable Diffusion Inpainting is a latent diffusion model capable of inpainting images given any text input and a mask image.


ControlNet
Control image generation with text prompt and control image.


BERT
Neural network-based technique for natural language processing. Use it to train your own question answering system and more.


LayoutLM for VQA
Fine-tuned for document understanding and information extraction tasks like form and receipt understanding.


ViLT VQA
Vision-and-Language Transformer (ViLT) model fine-tuned on VQAv2.


OWL-ViT
Zero-shot, text-conditioned object detection model that can query an image with one or multiple text queries.


CLIP
Neural network capable of classifying images without prior training on the classes.


BLIP VQA
A Vision-Language Pre-training (VLP) framework for visual question answering (VQA).


BLIP image captioning
A Vision-Language Pre-training (VLP) framework for image captioning.


Embeddings for Multimodal
Generates vectors based on images, which can be used for downstream tasks like image classification, image search, and so on.

All partners
Open models on Hugging Face
Deploy some of the most popular open source models from Hugging Face to Vertex AI.


MiniMaxAI/MiniMax-M2.1
Text generation

LiquidAI/LFM2-2.6B-Exp
Text generation

nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16
Text generation

deepseek-ai/DeepSeek-V3.2
Text generation

black-forest-labs/FLUX.1-dev
Text to image

openai/gpt-oss-20b
Text generation

meta-llama/Llama-3.1-8B-Instruct
Text generation

nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-FP8
Text generation

sentence-transformers/all-MiniLM-L6-v2
Sentence similarity

stabilityai/stable-diffusion-xl-base-1.0
Text to image

deepseek-ai/DeepSeek-OCR
Image text to text

openai/gpt-oss-120b
Text generation
Fine-tunable models
Models that data scientists can further fine-tune through a custom notebook or pipeline.


Gemma 3n
Lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models


Gemma 3
Lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models


Gemma 2
Lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models


Gemma
Lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models


Llama 3.1
SoTA open LLM built by Meta.


Llama 3.3
Explore and build with Llama 3.3 models on Vertex AI.


Llama 3.2
SoTA open LLM built by Meta.


Llama 3
SoTA open LLM built by Meta.


Mixtral
A Mixture of Experts LLM series developed by Mistral AI.


GPT OSS
OpenAI's open-weight models designed for powerful reasoning, agentic tasks, and versatile developer use cases


Qwen3
Explore and build with Qwen3 models on Vertex AI.


DeepSeek-R1
Serve with deepseek-ai/deepseek-r1 models.


Phi-3
Explore and build with Phi-3 models on Vertex AI.


Qwen2 & Qwen2.5
Explore and build with Qwen2 and Qwen2.5 models on Vertex AI.


CloudNeRF
The CloudNeRF model blends cutting-edge research from Zip-NeRF (Anti-Aliased Grid-Based Neural Radiance Fields) and CamP (Camera Preconditioning). This card provides two distinct implementations to suit your workflow. Camp-ZipNeRF (JAX framework) leverages the power of the JAX framework for numerical computation and automatic differentiation, prioritizing efficiency and accurate 3D reconstruction from 2D images. Pytorch-ZipNeRF (Pytorch framework) offers a state-of-the-art implementation of the ZipNeRF algorithm within the popular PyTorch deep learning framework.


AutoGluon
With AutoGluon you can train and deploy high-accuracy machine learning and deep learning models for tabular data.


Mistral Self-host (7B & Nemo)
Mistral is a family of language model engineered for superior performance and efficiency.


Code Llama
Meta's family of code models designed for code synthesis, understanding and instruction available in four sizes.


MoViNet Video Action Recognition
MoViNets (Mobile Video Networks) provide a family of efficient video classification models. The classification model supports video action recognition tasks with proper data preparation and inference algorithms.


AutoML Vision Image Object Detection
AutoML Vision Image Object Detection enables you to train machine learning models to perform object detection tasks based on your own defined labels.


AutoML Vision Image Classification
AutoML Vision Image Classification enables you to train machine learning models to classify your images according to your own defined labels.


Stable Diffusion XL
Latent text-to-image diffusion model capable of generating high fidelity images given a text input.


YOLOv8 (Keras)
YOLOv8 is a one-stage object detection algorithm that can achieve real-time performance on a single GPU.


MoViNet Video Clip Classification
MoViNets (Mobile Video Networks) provide a family of efficient video classification models, supporting inference of streaming video and on mobile devices.


tfvision/YOLOv7 [deprecated]
YOLOv7 is a one-stage object detection algorithm that can achieve real-time performance on a single GPU.


Stable Diffusion v2.1
Latent text-to-image diffusion model taking as input a text prompt, and generates an image.


Falcon-instruct (PEFT)
Finetune and deploy Falcon-instruct with PEFT.


OpenLLaMA (PEFT)
Finetune and deploy OpenLLaMA with PEFT.


Proprietary/MaxViT [Deprecated]
MaxViT is a family of hybrid (CNN + ViT) image classification models. A Google internal dataset is used to pre-train this model. The pre-trained checkpoint will be loaded as the initial checkpoint. The derived models can be used in commercial products but the weights can not be exported.


Proprietary/YOLO
YOLOv7 is a one-stage object detection algorithm that can achieve real-time performance on a single GPU. A Google internal dataset is used to pre-train this model. The pre-trained checkpoint will be loaded as the initial checkpoint. The derived models can be used in commercial products but the weights can not be exported.


ViT (JAX)
ViT is a transformer-like architecture for image classification.


Embeddings for Text
Converts text data into vector representations for semantic search, classification, clustering, and similar tasks.


Proprietary/EfficientNet [Deprecated]
EfficientNetV2 uses a variation of convolutional neural network searched from a search space enriched with new ops such as Fused-MBConv. A Google internal dataset is used to pre-train this model. The pre-trained checkpoint will be loaded as the initial checkpoint. The derived models can be used in commercial products but the weights can not be exported.


Proprietary/Spinenet [Deprecated]
RetinaNet object detection model using SpineNet backbone. A Google internal dataset is used to pre-train this model. The pre-trained checkpoint will be loaded as the initial checkpoint. The derived models can be used in commercial products but the weights can not be exported.


Proprietary/ViT [Deprecated]
ViT is a transformer-based architecture for image classification. A Google internal dataset is used to pre-train this model. The pre-trained checkpoint will be loaded as the initial checkpoint. The derived models can be used in commercial products but the weights can not be exported.


Mask R-CNN (Detectron2)
Mask R-CNN is an instance segmentation model which extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition.


RetinaNet (Detectron2)
RetinaNet is a one-stage object detection model that utilizes a feature pyramid network (FPN) on top of a ResNet and adds a focal loss function to address class imbalance during training.


ControlNet
Control image generation with text prompt and control image.


Faster R-CNN (Detectron2)
Faster R-CNN is a deep convolutional network used for image object detection.


tfvision/YOLO [deprecated]
YOLO algorithm is a one-stage object detection algorithm that can achieve real-time performance on a single GPU.


DeepLabv3+ (with checkpoint)
Semantic segmentation is the task of assigning a label to each pixel in an image, where each label corresponds to a specific class of object or scene element.


ResNet (with checkpoint)
Image classification model as described in the paper "Deep Residual Learning for Image Recognition".


tfvision/vit [deprecated]
The Vision Transformer (ViT) is a transformer-based architecture for image classification.


tfhub/EfficientNetV2 [deprecated]
EfficientNet V2 are a family of image classification models, which achieve better parameter efficiency and faster training speed than prior arts.

Task-specific solutions
Most of these pre-built models are ready to use off the shelf, and many can be customized using your own data.


Translation LLM
The best performing translation model, finetuned from Gemini specifically for translating text between languages. Brought to you by the team who brought Google Translate to enterprise.


Codestral 2
A cutting-edge model specifically designed for code generation, including fill-in-the-middle and code completion.


Codestral (25.01) (Self-Deploy)
A cutting-edge model specifically designed for code generation, including fill-in-the-middle and code completion.


Jamba Large 1.6
Jamba Large 1.6 offers fast, high-quality performance with superior long context handling and speed.


Virtueguard-Text-Lite (Self-Deploy)
This model is trained to monitors AI outputs, ensuring they remain aligned with safety and security protocols in real-time.


Contextual AI Reranker (Self-Deploy)
Instruction following reranker with best in class price-performance and available in multiple sizes.


Voyage 3.5-lite
Cost-optimized text embedding model delivering high-quality retrieval performance with 6.5x lower cost than OpenAI-v3-large while maintaining superior accuracy.


Cube by CSM
Cube by CSM is an AI model that transforms 2D images into production-ready 3D models.


Qodo-Embed-1-7B
A suite of large-scale state-of-the-art code embedding models for efficient code & text retrieval, enhancing the search accuracy of RAG methods.


voyage-multimodal-3.5
Rich multimodal embedding model that can vectorize interleaved text, content-rich images, and video. 32K context length.


voyage-4-lite
Text embedding model optimized for general-purpose retrieval quality, latency, and cost for AI applications. 32K context length.


voyage-4
Text embedding model optimized for general-purpose (including multilingual) retrieval/search and AI applications. 32K context length.


voyage-4-large
State-of-the-art text embedding model with the best general-purpose and multilingual retrieval quality. 32K context length.


SEA-LION v4
A collection of Large Language Models pretrained and instruct-tuned for the Southeast Asia region.


Video Speech Transcription
Useful for transcribing the speech in video.


Video Text Detection
Useful for detecting visible text in video.


BiomedCLIP
Zero-shot image classification with the BiomedCLIP biomedical vision-language foundation model.


MoViNet Video Action Recognition
MoViNets (Mobile Video Networks) provide a family of efficient video classification models. The classification model supports video action recognition tasks with proper data preparation and inference algorithms.


Bytetrack Multi-Object Tracking
ByteTrack is a multi-object tracking model that detects, identifies, and tracks objects across video frames.


MoViNet Video Clip Classification
MoViNets (Mobile Video Networks) provide a family of efficient video classification models, supporting inference of streaming video and on mobile devices.


Pic2Word Composed Image Retrieval
Pic2Word is a state of the art image retrieval model.


Text Translation
Use Google's proven pre-trained text model to get text translations for 100+ languages.


Text Moderation
Text moderation analyzes a document and returns a list of harmful and sensitive categories that apply to the text found in the document.


Watermark detector
Watermark detector is a prebuilt model that detects watermarks in the input image.


Text detector (Vision API)
Text detector detects and extracts text from images. It uses optical character recognition (OCR) for an image to recognize text and convert it to machine coded text.


TabNet
TabNet is a general model which performs well on a wide range of classification and regression tasks.


Form Parser
Document AI Form Parser applies advanced machine learning technologies to extract key-value pairs, checkboxes, tables from documents in over 200+ languages.


Face detector (Vision API)
Face detector is a prebuilt Vision API model that detects multiple faces in media (images, video) and provides bounding polygons for the face and other facial "landmarks" along with their corresponding confidence values.


Document AI OCR processor
Document OCR can identify and extract text from documents in over 200 printed languages and 50 handwritten languages.


Content moderation (Vision)
Content Moderator (Vision) detects objectionable or unwanted content across predefined content labels (e.g., adult, violence, spoof) or custom labels provided by the user.


AutoML Tabular Workflow
Tabular Workflow for End-to-End AutoML is the complete AutoML pipeline for classification and regression tasks.


Tag recognizer
Extract text in product and price tags


Product recognizer
Identify products at the GTIN or UPC level


Person blur
Mask or blur a person's appearance in video


PPE detector
Identify people and personal protective equipment (PPE).


Object detector
Identify and locate objects in video


Syntax analysis
Syntactic analysis extracts linguistic information, breaking up the given text into a series of sentences and tokens (generally, word boundaries), providing further analysis on those tokens.


Entity sentiment analysis
Entity Sentiment Analysis inspects the given text for known entities (proper nouns and common nouns), returns information about those entities, and identifies the prevailing emotional opinion of the entity within the text, especially to determine a writer's attitude toward the entity as positive, negative, or neutral.


Sentiment analysis
Sentiment analysis attempts to determine the overall attitude (positive or negative) expressed within the text. Sentiment is represented by numerical score and magnitude values.


Content classification
Use Google's state-of-the-art language technology to analyzes text content and returns content categories for the content. The latest version of Content Classification supports over 1,000 categories.


Person/vehicle detector
Detects and counts people and vehicles in video.


Entity analysis
Inspect text to identify and label persons, organizations, locations, events, products and more.


Occupancy analytics
Detect people and vehicles in a video or image, plus zone detection, dwell time, and more.

